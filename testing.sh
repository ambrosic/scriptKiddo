#!/bin/bash
#SBATCH --nodes=1 --ntasks=6
#SBATCH --time=1:00:00
#SBATCH --mem=6G
#SBATCH --gres=gpu:1

module load foss/2022a CUDA/11.7.0

cd ~/ambrosic/FluidX3D/
echo "CUDA_VISIBLE_DEVICES ${CUDA_VISIBLE_DEVICES} \
GPU_DEVICE_ORDINAL ${GPU_DEVICE_ORDINAL} \
HOSTNAME ${HOSTNAME} \
SLURMD_NODENAME ${SLURMD_NODENAME} \
SLURM_CHECKPOINT_IMAGE_DIR ${SLURM_CHECKPOINT_IMAGE_DIR} \
SLURM_CLUSTER_NAME ${SLURM_CLUSTER_NAME} \
SLURM_CPUS_ON_NODE ${SLURM_CPUS_ON_NODE} \
SLURM_GTIDS ${SLURM_GTIDS} \
SLURM_JOBID ${SLURM_JOBID} \
SLURM_JOB_ACCOUNT ${SLURM_JOB_ACCOUNT} \
SLURM_JOB_CPUS_PER_NODE ${SLURM_JOB_CPUS_PER_NODE} \
SLURM_JOB_GID ${SLURM_JOB_GID} \
SLURM_JOB_GPUS ${SLURM_JOB_GPUS} \
SLURM_JOB_ID ${SLURM_JOB_ID} \
SLURM_JOB_NAME ${SLURM_JOB_NAME} \
SLURM_JOB_NODELIST ${SLURM_JOB_NODELIST} \
SLURM_JOB_NUM_NODES ${SLURM_JOB_NUM_NODES} \
SLURM_JOB_PARTITION ${SLURM_JOB_PARTITION} \
SLURM_JOB_QOS ${SLURM_JOB_QOS} \
SLURM_JOB_UID ${SLURM_JOB_UID} \
SLURM_JOB_USER ${SLURM_JOB_USER} \
SLURM_LOCALID ${SLURM_LOCALID} \
SLURM_MEM_PER_NODE ${SLURM_MEM_PER_NODE} \
SLURM_NNODES ${SLURM_NNODES} \
SLURM_NODEID ${SLURM_NODEID} \
SLURM_NODELIST ${SLURM_NODELIST} \
SLURM_NODE_ALIASES ${SLURM_NODE_ALIASES} \
SLURM_PRIO_PROCESS ${SLURM_PRIO_PROCESS} \
SLURM_PROCID ${SLURM_PROCID} \
SLURM_SUBMIT_DIR ${SLURM_SUBMIT_DIR} \
SLURM_SUBMIT_HOST ${SLURM_SUBMIT_HOST} \
SLURM_TASKS_PER_NODE ${SLURM_TASKS_PER_NODE} \
SLURM_TASK_PID ${SLURM_TASK_PID} \
SLURM_TOPOLOGY_ADDR ${SLURM_TOPOLOGY_ADDR} \
SLURM_TOPOLOGY_ADDR_PATTERN ${SLURM_TOPOLOGY_ADDR_PATTERN} \
SLURM_WORKING_CLUSTER ${SLURM_WORKING_CLUSTER} \
TERM ${TERM} \
TMPDIR ${TMPDIR} \
USER ${USER}"
ls
#source /make.sh
